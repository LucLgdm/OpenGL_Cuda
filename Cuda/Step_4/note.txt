RÃ©duction (sum)

Somme de tous les Ã©lÃ©ments dâ€™un tableau (utiliser dâ€™abord la mÃ©moire globale, puis optimiser avec la mÃ©moire partagÃ©e).

Variante : calcul du maximum ou moyenne.

Produit scalaire (dot product)

Deux vecteurs A et B â†’ rÃ©sultat scalaire sum(A[i]*B[i]).

Bon exercice pour combiner parallÃ©lisme + rÃ©duction.

Transpose de matrice

Ã‰changer les lignes et colonnes dâ€™une matrice NÃ—N.

Commencer avec mÃ©moire globale simple, puis lâ€™optimiser avec tiling en mÃ©moire partagÃ©e (Ã©vite les accÃ¨s non coalescÃ©s).

Multiplication Hadamard (Ã©lÃ©ment par Ã©lÃ©ment)

Simple C[i][j] = A[i][j] * B[i][j].

Sert Ã  bien comprendre mapping (row, col) â†” threadIdx.

ğŸ”¹ Exercices intermÃ©diaires

Histogramme

Ã€ partir dâ€™un tableau dâ€™entiers (par ex. entre 0 et 255), compter le nombre dâ€™occurrences de chaque valeur.

DifficultÃ© : plusieurs threads veulent incrÃ©menter la mÃªme case â†’ introduction des atomic operations.

Convolution 2D (filtrage image)

Appliquer un petit kernel (3Ã—3 par exemple) sur une matrice qui reprÃ©sente une image.

Introduit la notion de fenÃªtres glissantes et de dÃ©pendances locales.

Prefix sum (scan)

Calcul des prÃ©fixes cumulatifs (ex : [1,2,3,4] â†’ [1,3,6,10]).

Sert beaucoup en algorithmique parallÃ¨le.

ğŸ”¹ Exercices visuels (motivation GPU ğŸ˜„)

Julia / Mandelbrot set

GÃ©nÃ©rer une fractale en parallÃ¨le : un thread = un pixel.

TrÃ¨s bon pour pratiquer grilles 2D + mapping (x, y) vers coordonnÃ©es image.

Ray casting 2D simple

Chaque thread calcule la couleur dâ€™un pixel en fonction de la direction dâ€™un rayon.

Une premiÃ¨re approche avant un vrai ray tracer CUDA.